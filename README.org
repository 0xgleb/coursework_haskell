* Introduction

  The purpose of this project is to compare to popular languages in different programming paradigms: Haskell vs Python. Haskell is one of the most popular functional programming languages and one of the most "functional" in the sense that it doesn't support imperative programming or OOP. If you type into Google "Haskell vs " the first thing that comes up is "Haskell vs Python" which is one of the reasons I decided to compare Haskell with Python. Also Python is very different to Haskell, so we can compare lots of different aspects and different ideas.

  Here are some differences between Haskell and Python:

  |---------------------+------------------------------+----------------------------------------------------------------------|
  |                     | Haskell                      | Python                                                               |
  |---------------------+------------------------------+----------------------------------------------------------------------|
  | Paradigms           | Functional                   | OOP, imperative, procedural. Has elements of functional programming. |
  | Evaluation strategy | Lazy/non-strict              | Strict                                                               |
  | Type system         | Static, strong inferred      | Dynamic, strong, duck.                                               |
  | Execution (default) | Compiled or intepreted (GHC) | Interpreted (CPython)                                                |
  |---------------------+------------------------------+----------------------------------------------------------------------|

  Python is one year younger than Haskell and some of it's features were influenced by Haskell.
  
* Basics of Haskell

  Most programmers know Python to some extend, however very few people know Haskell. This is why I'm going to start this comparison by introducing basics of Haskell.

** Hello World +

   #+BEGIN_SRC haskell
   main :: IO ()
   main = print "Hello World!"
   #+END_SRC

   Now let's write a console program that asks the user for their name and then prints "Hello <username>!"

   Haskell's IO parts of the program can look very similar to "normal" languages.

   #+BEGIN_SRC haskell
   main :: IO ()
   main = do
       print "What's your name?"
       name <- getLine
       print ("Hello " ++ name ++ "!")
   #+END_SRC

   But we can write this in functional style and it would look like this:

   #+BEGIN_SRC haskell
   main :: IO ()
   main = print "What's your name?" >> getLine >>= print . (++ "!") . ("Hello " ++)
   #+END_SRC

   This does exactly the same thing. First it prints "What's your name", then it reads user's input and then redirects it to ~print . (++ "!") . ("Hello " ++)~. This is a composition prints the result after adding the lines. This is a more compact way of writing that and it doesn't use the ~name~ variable.

** Function purity

   Haskell is very different from most languages. In Haskell all your variables are immutable. This means that you don't really have variables, you only have constants. Also in Haskell all functions are pure. A pure function is such a function that any time it gets called with the same arguments returns the same result. This means that functions can't modify global state and don't get effected by anything that happens. This makes pure functions very easy to test and it makes code debugging much easier.

** Lazy evaluation

   Another thing that is makes Haskell very different from typical programming languages is the fact that by default it uses lazy evaluation. This means that functions won't get evaluated until their results are needed. This means that when a program is executed it won't do unnecessary computations. I talk more about evaluation strategies in Haskell and how it's different from the one used in Python further in this coursework.

** Defining functions

   Let's define the square function ~f~ in both Python and Haskell. Here is how it would look like in Python:

   #+BEGIN_SRC python
   def f(x, y):
       return x*x + y*y
   #+END_SRC

   And now in Haskell:
   
   #+BEGIN_SRC haskell
   f x y = x*x + y*y
   #+END_SRC

   In Haskell to pass arguments into a function we don't use brackets and/or commas, we separate arguments with spaces. As you can see the definition is very simple and it doesn't use any unnecessary syntax like ~def~ or ~return~. It's just function name, arguments and what it returns.

   In Haskell functions and types are the two primary things and everything is centered around them, so it makes sense why it's very easy to define them.

** Introduction to the type system

   In Haskell you don't need to explicitly define types of functions or variables, the compiler will derive it for you. However, it's one of the best practices to explicitly write function and variable types. Let's define the previous function with a type now and then write the main function to test the ~f~ function.

   #+BEGIN_SRC haskell
   f :: Int -> Int -> Int
   f x y = x*x + y*y

   main = print (f 2 3)
   #+END_SRC

   But what if we want function ~f~ to work with all numbers and not just integers. The first solution to that would be to not define the type of ~f~, in that case our file would look like this:

   #+BEGIN_SRC haskell
   f x y = x*x + y*y

   main = print (f 2.1 4)
   #+END_SRC

   GHC (Glasgow Haskell Compiler) is the default Haskell compiler. However, because Haskell can be both compiler and intepreted there is an interactive environment GHCi, which you can use to run code without making a file for it. It can also tell us the type of that function, so let's use it to find the type.

   #+BEGIN_SRC haskell
   Prelude> :load sum_squares.hs 
   [1 of 1] Compiling Main             ( sum_squares.hs, interpreted )
   Ok, modules loaded: Main.
   *Main> :t f
   f :: Num a => a -> a -> a
   *Main> 
   #+END_SRC

   Ok, let's figure out what that type is.

   | Type         | Meaning                                                                          |
   |--------------+----------------------------------------------------------------------------------|
   | Int          | Integer type                                                                     |
   | Int -> Int   | A function that takes an integer and returns an integer                          |
   | Float -> Int | A function that takes a float and returns an integer                             |
   | a -> Int     | A function that takes a value of any type and returns an integer                 |
   | a -> a       | A function that takes a value of any type and returns something of the same type |

   In Haskell type ~a -> a -> a~ is the same as ~a -> (a -> a)~. This means that this function takes a value of any type and returns a function that takes an argument of the same type and returns something of the same type, so basically it's a function with two arguments. The benefit of that is that we can give the function only one argument and get a valid expression which is a function. This is called partial application.

   When in a type declaration you see something starting with a small letter, it means that it's a type variable. Type variables give us parametric polymorphism. Also, for example, if you have a function that takes two arguments of any type, but both arguments have the same type, you can specify that using type variables.

   But our function type is not just ~a -> a -> a~, it also has prefix ~Num a =>~. This means that type a is in the type class ~Num~. Type classes are like interfaces in OOP languages. They define a list of variables and/or functions. A type is in the type class if it implements all the functions from the type class.

   #+BEGIN_SRC haskell
   class Num a where
     (+) :: a -> a -> a
     (-) :: a -> a -> a
     (*) :: a -> a -> a
     negate :: a -> a
     abs :: a -> a
     signum :: a -> a
     fromInteger :: Integer -> a
   #+END_SRC

   Here is the definition of the type class ~Num~. In Haskell operators are just normal functions, so we can define them like that. So by writing ~Num a =>~ we restrict all possible types only to the ones that implement the functions listed above. We are going to come back to type classes later.

   So the type ~Num a => a -> a -> a~ means that it's a function that takes a number and returns a function that takes another number of the same type and then returns a number of the same type. Technically all functions in Haskell take only one argument. But any function that takes two arguments can be represented as a function that takes one argument and returns a function. So the expression ~f 3 4~ is equivalent to ~(f 3) 4~ and ~f 3~ is a function.

   To create functions we can use another form - lambda functions.
   
   #+BEGIN_SRC haskell
   f = \x y -> x*x + y*y
   #+END_SRC

** Basic minimum of Haskell

   Ok, now let's go through the basics of any programming language.

*** Arithmetics

    #+BEGIN_SRC haskell
    3 + 2 * 6 / 3 <=> 3 + ((2 * 6) / 3)
    #+END_SRC

*** Logic

    #+BEGIN_SRC haskell
    True || False <=> True
    True && False <=> False
    True == False <=> False
    True /= False <=> True
    #+END_SRC

*** Powers

    #+BEGIN_SRC haskell
    x ^ n  -- for non-negative integer powers
    x ** y -- for floating numbers
    #+END_SRC

*** Lists

    #+BEGIN_SRC haskell
    []             -- empty list
    [1, 2, 3]      -- a list of numbers
    ["foo", "bar"] -- a list of strings
    1:[2, 3]       -- [1, 2, 3]. (:) prepends an element to a list
    1:2:[]         -- [1, 2]
    [1,2] ++ [3,4] -- [1, 2, 3, 4]. (++) joins two lists
    [1,2] ++ ["?"] -- compilation error
    [1..4]         -- [1, 2, 3, 4]
    [1,3..10]      -- [1, 3, 5, 7, 9]
    [2,3,5,7..100] -- error, the compiler is not that smart
    [5,4..1]      -- [5, 4, 3, 2, 1]
    #+END_SRC

*** String

    In Haskell strings are just lists of chars.

    #+BEGIN_SRC haskell
    'a' :: Char
    "a" :: [Char] -- :: String
    "ab" -- ['a', 'b']
    #+END_SRC

*** Tuples

    #+BEGIN_SRC haskell
    -- All of these tuples are valid
    (2,"foo")
    (3,'a',[2,3])
    ((2,"a"),"c",3)

    fst (x, y) = x
    snd (x, y) = y

    fst (x, y, z) -- ERROR: fst :: (a, b) -> a
    snd (x, y, z) -- ERROR: snd :: (a, b) -> b
    #+END_SRC

** Applying functions

   Here are two useful operator that are used very often.

   #+BEGIN_SRC haskell
   (.) :: (b -> c) -> (a -> b) -> a -> c
   (.) f g x = f (g x)

   ($) :: (a -> b) -> a -> b
   ($) f x = f x
   #+END_SRC

   Here are some examples:

   #+BEGIN_SRC haskell
   f g h x = (((f g) h) x)

   f g $ h x   = f g (h x)
   f $ g h x   = f (g h x) = f ((g h) x)
   f $ g $ h x = f (g (h x))

   (f . g) x     = f . g $ x     = f (g x)
   (f . g . h) x = f . g . h $ x = f (g (h x))
   #+END_SRC

** More on the syntax

*** Infix and prefix notation

    #+BEGIN_SRC haskell
    square :: Num a => a -> a
    square x = x ^ 2
    #+END_SRC

    Any infix operator can be used in prefix notation.

    #+BEGIN_SRC haskell
    square' x = (^) x 2
    square'' x = (^2) x
    #+END_SRC

    We can remove ~x~ from the right hand side, this is called η-reduction.

    #+BEGIN_SRC haskell
    square''' = (^2)
    #+END_SRC

    All these functions are identical.
    
    And functions in Haskell can be used in infix notation as well.

    #+BEGIN_SRC haskell
    add :: Num a => a -> a -> a
    add = (+)

    5 `add` 4 = add 5 4 = 9
    #+END_SRC

*** Conditions

    Type class ~Ord~ is for types that can be ordered.

    #+BEGIN_SRC haskell
    absolute :: (Ord a, Num a) => a -> a
    absolute x = if x >= 0 then x else -x
    #+END_SRC

    In Haskell if statements must always have ~then~ and ~else~.

    Here is another way to write that function:

    #+BEGIN_SRC haskell
    absolute' x
        | x >= 0 = x
        | otherwise = -x
    #+END_SRC

    In Haskell indentation is very important. Just like in Python programs with incorrect indentation will not work or, in some cases, will work, but not the way it was intended. Haskell uses spaces instead of tabs, if you try to use tabs then the program won't compile.

** Functional style

   Let's introduce a problem and then solve it using first Python and then Haskell.

   We want a function that takes a list of integers and returns the sum of all even numbers in that list.

   #+BEGIN_SRC
   [1, 2, 3, 4, 5] -> 2 + 4 -> 6
   #+END_SRC

   #+BEGIN_SRC python
   def evenSum(l):
       result = 0
       for x in l:
           if(x % 2 == 0):
               result += x
       return result  
   #+END_SRC

   We can't implement it in Haskell exactly the same way because it doesn't have loops or variables. So here is how we can implement it in Python without mutating variables and using loops.

   #+BEGIN_SRC python
   def accumSum(l, n):
       if(len(l) == 0):
           return n
       else:
           x, *xs = l
           if(x % 2 == 0):
               return accumSum(xs, x + n)
           else:
               return accumSum(xs, n)

   def evenSum(l):
       return accumSum(l, 0)
   #+END_SRC

   Before we start, here are some Haskell function we'll use.

   #+BEGIN_SRC haskell
   even :: Integral a => a -> Bool -- returns True if the given number is even
   head :: [a] -> a                -- returns the first element of the given list
   tail :: [a] -> [a]              -- returns the given list without the first element
   #+END_SRC

   Here is our first solution:

   #+BEGIN_SRC haskell
   evenSum :: [Integer] -> Integer
   evenSum l = accumSum 0 l

   accumSum :: Integer -> [Integer] -> Integer
   accumSum n l = if l == []
                     then n
                     else let x  = head l
                              xs = tail l
                          in if even x
                                then accumSum (n+x) xs
                                else accumSum n xs
   #+END_SRC

   We can do several improvements to this piece of code. First we can make the type definition more general (without changing the implementation).

   #+BEGIN_SRC haskell
   evenSum :: Integral a => [a] -> a
   #+END_SRC

   We don't want ~accumSum~ to be a global variable, so we can make it local using ~where~ clause. Also we can use pattern matching instead of ~head~ and ~tail~. Then we can use η-reduction to get this:

   #+BEGIN_SRC haskell
   evenSum :: Integral a => [a] -> a
   evenSum = accumSum 0
       where accumSum n []     = n
             accumSum n (x:xs) = if even x
                                    then accumSum (n+x) xs
                                    else accumSum x xs
   #+END_SRC

   Pattern matching is using values instead of variable arguments. We can't use any function we want on the left side - only type constructors, which I will discuss later.

   We can simplify this even more using higher order functions.

** Higher order functions

   Higher order functions are functions that take another function as one of the arguments. Here are several examples:

   #+BEGIN_SRC haskell
   filter :: (a -> Bool) -> [a] -> [a]
   map    :: (a -> b) -> [a] -> [b]
   foldl  :: (a -> b -> a) -> a -> [b] -> a
   #+END_SRC

   Function ~filter~ takes a function of type ~a -> Bool~ and a list ~[a]~. It returns a list that only contains the elements of the given list that return ~True~ when the given function is applied.

   ~map~ takes a function and a list and applies the function to every element of the list.

   #+BEGIN_SRC haskell
   filter even [1..5] = [2, 4]

   map (*2) [1..5] = [2,4,6,8,10]
   #+END_SRC

   So let's use this.

   #+BEGIN_SRC haskell
   evenSum l = mysum $ filter even l
       where mysum []     = 0
             mysum (x:xs) = x + mysum xs
   #+END_SRC

** Making types
** Recursive types
** Infinite structures
** Functors
** Applicative functors
** Monads
** IO

* Procedural, object orientied, and functional programming.
** Imperative and declarative programming
   *Imperative programming* is a programming paradigm that uses statements that change a program's state.

   *Declarative programming* is a programming paradigm that expresses the logic of a computation without describing the order of instructions. It tries to describe what needs to be accomplished instead of describing how to accomplish it.

   So the difference between imperative programming and declarative programming is that declarative programming doesn't specify the order of instructions.
** Expressiveness
   
   Let's take a look at several code examples in Python and Haskell.

*** Hello World

    Python:

    #+BEGIN_SRC python
    print "Hello World"
    #+END_SRC

    Haskell:

    #+BEGIN_SRC haskell
    main :: IO () -- type declaration is not necessary, if I didn't specify it then the compiler would derive it
    main = print "Hello World"
    #+END_SRC

*** A program that reads a name and print "Hello <username>"

    Python:

    #+BEGIN_SRC python

    #+END_SRC

    Haskell (procedural IO style):

    #+BEGIN_SRC haskell
    main :: IO ()
    main = do name <- getLine
              print ("Hello " ++ name)
    #+END_SRC

    Haskell (functional style):

    #+BEGIN_SRC haskell
    main :: IO ()
    main = getLine >>= print . ("Hello " ++)
    #+END_SRC

** Polymorphism

   Both Haskell and Python have polymorphism, however there are sertain differences. Haskell doesn't support OOP, so it has a different types of polymorphisms: parametric polymorphism and ad hoc polymorhpism. For parametric polymorphism Haskell uses type variables.

   For example, let's take a look at identity function.

   #+BEGIN_SRC haskell
   id :: a -> a
   id x = x
   #+END_SRC

   ~a~ can be replaced with any type. If we want to use a type that has specific function implemented for it then we use type classes. A type class defines a list of variables and/or functions. A type implements the type class if it implements all the functions.

   #+BEGIN_SRC haskell
   class Show a where
       show :: a -> String

   data Example = Example

   instance Show Example where
       show Example = "Example"
   #+END_SRC

   Now we can use this with parametric polymorhpism.

   #+BEGIN_SRC haskell
   showAndReverse :: Show a => a -> String
   showAndReverse = reverse . show
   #+END_SRC

* Haskell vs functional elements of Python
* Strict and lazy/non-strict evaluation

  Haskell has a very interesting execution scheme. It doesn't execute expressions until it needs the result. It can make our code simpler and more modular, but it can also be confusing wheen it comes to estimating performance and memory usage. For example this simple expression that sums all numbers from 1 to 10^8 ~foldl 0 [1..10^8]~ requires gigabytes of memory to evaluate. But if we import the strict version of this funciton ~foldl'~ from the ~Data.List~ module, everything's ok.

** How lazy evaluation in Haskell works?

*** Graph reduction

    Haskell programs are executed by evaluating expressions. The primary idea is function application. Here is a simple function:

    #+BEGIN_SRC haskell
    square x = x*x
    #+END_SRC

    Let's see how the following expression gets evaluated:

    #+BEGIN_SRC haskell
    square (1+2)
    => (1+2)*(1+2) -- replacing the left hand side
    => 3*(1+2)
    => 3*3
    => 9
    #+END_SRC

    We calculated ~(1+2)~ twice, to avoid that we use graph reduction method. In this graph every block is a function application. Our situation can be represented by the following graph:

    [[https://hackhands.com/data/blogs/ClosedSource/lazy-evaluation-works-haskell/assets/blocks-square-0.png]]

    This representation is similar to the way the compiler actually represents expressions with pointers. When a programmer defines a function they define a reduction rule, then when the function is applied the graph gets reduced until it becomes a basic expression. Any expression can be represented using graphs.

    Our function corresponds with this rule:

    [[https://hackhands.com/data/blogs/ClosedSource/lazy-evaluation-works-haskell/assets/blocks-square-rule.png]]
    
    ~x~ is a placeholder for a subgraph. And when arguments get duplicated they point to the same subgraph, hence identical graphs don't get reduced multiple times.

    Any subgraph that follows the rules is called a reducible expression or redex. In our case with have two redexes: function ~square~ and addition ~+~. If we start with ~square~ then we'll get this:

    [[https://habrastorage.org/getpro/habr/post_images/295/429/ede/295429ede71982a0ce68544095ffed35.png]]

    At every step the highlighted rectangle gets updated.

*** Normal form

    If the graph is not a redex then it means that we already reduced everything and got the result that we wanted. In the last example the normal form was a number, but constructors of algebraic data types like ~Just~, ~Nothing~, or lists constructors ~:~ and ~[]~ are not reducible. Even though these are functions they can't be reduced, that's because they were defined using ~data~ and don't have a right-hand side. For example, graph:

    [[https://habrastorage.org/getpro/habr/post_images/bd7/1ca/4f6/bd71ca4f639ea360db4b9966446e5459.png]]

    By definition a normal graph needs to be finite and it shouldn't have cycles. Infinite recursion is not normal.

    #+BEGIN_SRC haskell
    ones = 1 : ones
    #+END_SRC

    Corresponds to the following cyclic graph.

    [[https://habrastorage.org/getpro/habr/post_images/76b/740/316/76b740316cb9f87f024dbe341cd65acc.png]]

    It's not a redex and also not in the normal form - the tail of the list points to the list itself, making an infinite recursion.

    In Haskell expressions usually don't get to the normal form. Quite often we stop when we get to the weak head normal form (WHNF). If a graph is in WHNF then it's top node is a constructor. Like expression ~(7+12):[]~ or graph

    [[https://habrastorage.org/getpro/habr/post_images/1ec/bb9/b87/1ecbb9b873d806a42ef7e5e42aa49a16.png]]

    is in WHNF, it's top node is a constructor of a list ~(:)~. And it's not the normal form because the first argument is a redex.

    List ~ones~ is also in WHNF, it's top node is a constructor. In Haskell we can create and use infinite lists! They work just fine.

** Execution order, lazy evaluation

   Often expressions have multiple redexes. Does the order at which we reduce them matter?

   Most languages use the strategy that reduces arguments to the normal form before reducing the function. However, most Haskell compilers use a different evaluation order called *lazy*. It first reduces the top function application. That may require calculating some of the arguments, but only as many as it needs. Let's take a look at this expression with pattern matching. The arguments will get evaluated from left to right until the top node contains a constructor. If pattern matching isn't used then the arguments don't get evaluated. If you pattern match a constructor then the argument gets reduced to WHNF.

   For example:

   #+BEGIN_SRC haskell
   (&&) :: Bool -> Bool -> Bool
   True  && x = x
   False && x = False
   #+END_SRC

   This defines two reduction rules:

   [[https://habrastorage.org/getpro/habr/post_images/dc4/eed/151/dc4eed15184fe1bc3325378d5c7a1706.png]]

   [[https://habrastorage.org/getpro/habr/post_images/dc4/eed/151/dc4eed15184fe1bc3325378d5c7a1706.png]]

   Now let's take a look at this expression:

   #+BEGIN_SRC haskell
   ('H' == 'i') && ('a' == 'm')
   #+END_SRC

   Both of the arguments are redexes. Cause of pattern matching the first argument will get evaluated. Then the graph will get reduced without reducing the second argument.
   
** Performance

   It's not hard to prove that for lazy evaluation we would need fewer number of calculations or the same as for eager evaluation. Also it can compute expressions with errors in it, such as

   #+BEGIN_SRC haskell
   a = 1
   b = 2
   (a == b) && (1 == (b/0))
   #+END_SRC

   The second argument of ~(&&)~ will never get evaluated, hence the second argument of the second ~(==)~ will never get evaluated, thus we'll never divide by zero and get an exception.

   However, if we look at the memory usage we can get some problems. Sometimes an expression reduced to normal form can use more memory than a redex, and it's vice versa. Let's take a look at examples of both cases.

   #+BEGIN_SRC haskell
   enumFromTo 1 1000
   #+END_SRC

   This expression generates a list with numbers from 1 to 1000. The list itself takes much more space than the expression.

   On the other hand we have situations where a simple expression would use ~foldl 0 [1..10^8]~ gigabytes of RAM to evaluate lazily.
   
   Here is another example:

   #+BEGIN_SRC haskell
   ((((0 + 1) + 2) + 3) + 4)
   #+END_SRC

   The graph that represents this expression takes more space than the normal form of the expression - ~10~.

   However Haskell allows you to force reduction using the ~seq~ combinator.

   #+BEGIN_SRC haskell
   seq :: a -> b -> b
   #+END_SRC

   If you look at the type signature you may think that it's exactly the same as the ~const~ function, however they are not the same. ~seq~ reduces the first argument to the WHNF and then returns the second argument. ~const~ doesn't do anything with the first argument. It's important to remember that ~seq~ doesn't reduce the first argument to the normal form. For example, if we are reading a list of lines ~l~ from a file, we can't just use ~seq l ...~ to force Haskell to finish reading the list. This would just force it to reading the first line, because that's enough to know the constructor. To force Haskell to finish reading the file we need to use ~seq (length l) ...~. The only way to reduce ~length l~ to the weak head normal form is to find the length, hence to read the entire file. But in other cases this might not work, for example ~length $ (+7) <$> [1..10]~ will find the length without adding any numbers.

   Here is a standard use case of ~seq~ that every Haskell programmer should know - strict left fold. Here is how ~foldl~ is defined in Prelude (Haskell's standard library):

   #+BEGIN_SRC haskell
   foldl :: (a -> b -> a) -> a -> [b] -> a
   foldl f a []     = a
   foldl f a (x:xs) = foldl f (f a x) xs
   #+END_SRC

   Say we want to sum all numbers from 1 to 100 (~[1..100]~). For that we would use the expression ~foldl (+) 0 [1..100]~. Here is how the evaluation process would look in that case:

   #+BEGIN_SRC haskell
   foldl (+) 0 [1..100]
   => foldl (+) 0 (1:[2..100])
   => foldl (+) (0 + 1) [2..100]
   => foldl (+) (0 + 1) (2:[3..100])
   => foldl (+) ((0 + 1) + 2) [3..100]
   ...
   #+END_SRC

* Algebraic data types vs classes
* Dynamic types vs static types
* Non-pure functions in Haskell and Python
* Debugging
* Fields vs lens
* Concurrency
* Use cases
